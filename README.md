# ğŸ§  Job Enrichment Pipeline

A suppressorâ€‘aware, modular pipeline for deduplicating, filtering, enriching, and narrating infrastructureâ€‘aligned job data. Built for remoteâ€‘first teams and recruiter review.

## ğŸ‘‹ Overview

This project transforms noisy job batches into auditâ€‘safe, narratable datasets. It reflects my engineering philosophy: suppressorâ€‘aware clarity, schema hygiene, and markdown storytelling.

## ğŸ§© Modules at a Glance (Pipeline Stages)

| Module                 | Pipeline Stage        | Purpose                                                                 | Output                                   |
|------------------------|------------------------|-------------------------------------------------------------------------|-------------------------------------------|
| `deduplication_stub.py` | **Stage 1 â€” Hygiene**     | Cleans encodings, patches corrupted text, suppresses malformed entries, deduplicates | `deduped_batch.json`, `suppressed_batch.json` |
| `filter_entries.py`     | **Helper Library**        | Roleâ€‘tag filters, techâ€‘stack filters, saturation checks, unfamiliarâ€‘tech suppressor | Used by `benchmark_runner.py` |
| `benchmark_runner.py`   | **Stage 2 â€” Enrichment**  | Applies filters, scores jobs and platforms, normalizes fields, narrates suppressions | `benchmarked_batch.json` |
| `narrate_batch.py`      | **Stage 3 â€” Summary**     | Generates batchâ€‘level markdown summary with score buckets and suppression breakdown | `infra_batch_summary.md` |
| `sql_import.py`         | **Stage 4 â€” Persistence** | Loads enriched data into SQLite for querying and dashboard use          | `jobs.db` |
| `md_exporter.py`        | **Stage 5 â€” Presentation**| Exports one markdown file per job and platform                          | `job_markdowns/`, `platform_markdowns/` |
| `run_pipeline.py`       | **Orchestrator**          | Runs all pipeline stages in sequence, halting on failure                | Full pipeline output |

ğŸš€ Running the Pipeline
- Take the role or job description you want to enrich.
- Use the current rawfeed_batch.json as a template (convert it using AI).
- Save the updated content into rawfeed_batch.json at the project root.
- Run:

    python run_pipeline.py

## ğŸ“¦ Outputs

- JSON: deduplicated, suppressed, and enriched batches  
- Markdown: recruiterâ€‘friendly summaries and individual entries  
- SQLite: structured querying and dashboardâ€‘ready data  
- All artifacts appear directly in the project directory    

## ğŸ§¼ Design Philosophy

- Suppressorâ€‘aware filtering and narration  
- Modular batch hygiene and techâ€‘fluency benchmarking  
- Markdown storytelling for recruiter clarity  
- SQLiteâ€‘backed persistence for auditâ€‘safe review  

## ğŸ§  Use Cases

- Cleaning and enriching jobâ€‘market datasets  
- Producing recruiterâ€‘ready summaries from noisy sources  
- Demonstrating suppressorâ€‘aware filtering and auditâ€‘safe data pipelines  
- Prototyping GenAIâ€‘ready ingestion and enrichment workflows  

## ğŸ”® Roadmap

- ONET title inference improvements  
- Wage tagging enhancements  
- Multiâ€‘source ingestion (HN, WWR, etc.)  
- Dashboard layer for batch insights  
- Agentic jobâ€‘matching workflow  

## ğŸ› ï¸ Tech Stack

- Python Â· JSON Â· Markdown Â· SQLite  
- `difflib`, `re`, `datetime`, `os`, `collections`  

---

ğŸ§  Built by Chad â€” diagnostic architect and workflow engineer  
ğŸ¯ Modularizing enrichment pipelines for infraâ€‘aligned clarity  
ğŸ“ GitHubâ€‘ready for recruiter review and remoteâ€‘first roles
